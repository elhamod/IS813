{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CECHXjp75AJY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamod/IS813/blob/main/Week6/IS883_2024_Week6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IS883 Week 10: RAG, ReAct, and CoT\n"
      ],
      "metadata": {
        "id": "qy7dgqvIEUEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use Google Colab for this assignment.\n",
        "\n",
        "2. **You are allowed to use ChatGPT for this assignment (except where specifically instructed). However, you may use Google and other online resources. As per the syllabus, you are required to cite your usage. You are also responsible for understanding the solution and defending it when asked in class.**\n",
        "\n",
        "3. For each question, fill in the answer in the cell(s) right below it. The answer could be code or text. You can add as many cells as you need for clarity.\n",
        "\n",
        "4. Enter your BUID (only numerical part) below, if applicable.\n",
        "\n",
        "5. **Your submission on Blackboard should be the downloaded notebook (i.e., ipynb file). It should be prepopulated with your solution (i.e., the TA and/or instructor need not rerun the notebook to inspect the output). The code, when executed by the TA and/or instructor, should run with no runtime errors.**"
      ],
      "metadata": {
        "id": "YT9rb6-K37DT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1: Pre-class Work"
      ],
      "metadata": {
        "id": "CECHXjp75AJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_community openai tiktoken faiss-cpu pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ycvq5d0Lfyz",
        "outputId": "bb7e9263-01c8-49ec-a5f3-815a7845e863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.46.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n",
            "Downloading openai-1.46.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.0/375.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m978.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.46.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: In-class Work"
      ],
      "metadata": {
        "id": "t-kHns05WFhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 RAG: Question Answering System Using the School's Syllabus Database"
      ],
      "metadata": {
        "id": "6QOIueVJiup4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " At your school, the department has embarked on a project to utilize language modeling for the development of a question-answering agent. This initiative aims to streamline the access to information for faculty and staff, particularly regarding the extensive array of courses offered at our institution. The data pertaining to these courses is currently dispersed across numerous documents within [the department's syllabus corpus](https://drive.google.com/drive/folders/1dH-t_Ujih4lMMzUOaNOHngvOYLK_gWOp?usp=sharing).\n",
        "\n",
        "Download the corpus to your Google Drive and update the path below.\n",
        "\n",
        "Note: The used syllabus corpus is a subset of [Cal Poly's Syllabus Corpus dataset](https://www.kaggle.com/datasets/mfekadu/syllabus-corpus)."
      ],
      "metadata": {
        "id": "CZyoG9F9_pYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "syllabus_corpus_path = \"/content/drive/MyDrive/IS883/Assignments/2023/IS883_HW4_syllabus_corpus\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeFveM1oAKFH",
        "outputId": "3118f2d6-719f-4e4d-936f-c9515616c146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use [PyPDFDirectoryLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.pdf.PyPDFDirectoryLoader.html) to create a loader that can load all the PDFs in the directory so they could be used by LangChain."
      ],
      "metadata": {
        "id": "s-5WoGlMB0HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "\n",
        "loader = PyPDFDirectoryLoader(syllabus_corpus_path)"
      ],
      "metadata": {
        "id": "9d5Kv4xOIbmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the extensive data contained within these documents, it's impractical to include them in their entirety in our queries. Including all data at once could exceed the context window's capacity and may result in significant processing costs. To address this challenge, we employ a methodical approach to manage the data effectively."
      ],
      "metadata": {
        "id": "K9BYOSrmCwdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)"
      ],
      "metadata": {
        "id": "pH5RHznSCv7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, using the afortmentioned loader and splitter, perform the splitting."
      ],
      "metadata": {
        "id": "NT_gyExVEK2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = loader.load_and_split(text_splitter)"
      ],
      "metadata": {
        "id": "tzrSsfNiELEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb052be-3969-4263-9c17-9198c145e39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 65 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 67 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 38 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 40 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 27 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 37 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 39 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 41 0 (offset 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next crucial step involves the creation of a data store, essentially a database, that will house the chunks of data you've created. The effectiveness of our question-answering system hinges on its ability to swiftly locate the relevant chunk containing the answer to any given query. To achieve this efficiency, we will employ a sophisticated indexing strategy, rather than relying on a basic brute-force search method.\n",
        "\n",
        "* Build the Data Store with [Facebook AI Similarity Search (FAISS)](https://python.langchain.com/docs/integrations/vectorstores/faiss): Set up your data store using a [FAISS Vector store](https://python.langchain.com/docs/integrations/vectorstores/faiss). FAISS is a library developed by Facebook AI that allows for efficient similarity search and clustering of dense vectors.\n",
        "\n",
        "* Embedding Calculation with `OpenAIEmbeddings`: For each chunk of data in your store, calculate an embedding using `OpenAIEmbeddings`. These embeddings are essentially numerical representations of your text data, which can then be compared to the embeddings of incoming queries.\n",
        "\n",
        "* Indexing for Efficient Search: By creating embeddings for each chunk and indexing them in the FAISS Vector store, you will enable the system to quickly find the most relevant chunk in response to a query. This process involves comparing the embedding of the query with the embeddings of the chunks to identify the best match.\n",
        "\n",
        "The combination of `FAISS` and `OpenAIEmbeddings` will significantly enhance the efficiency and accuracy of the question-answering system, allowing for rapid retrieval of information from the extensive syllabus corpus."
      ],
      "metadata": {
        "id": "kIkbtCboEWyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('MyOpenAIKey')\n",
        "\n",
        "faiss_index = FAISS.from_documents(chunks, OpenAIEmbeddings(openai_api_key=openai_api_key))"
      ],
      "metadata": {
        "id": "l1KJfaIHJW9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the data store and indexing system in place, you are now equipped to tackle the core functionality of our question-answering system: responding to queries based on the indexed database.\n",
        "\n",
        "* The code will utilize the [*`similarity_search`*](https://python.langchain.com/docs/integrations/vectorstores/faiss) function to identify the chunk that is most relevant or most similar to the posed question. This function will compare the embedding of the query with those of the indexed chunks to find the best match.\n",
        "\n",
        "* Once you have identified the most relevant answer, output additional details indicating where this chunk is located. Specifically, provide information about *the page number and the document from which this chunk was extracted*.\n",
        "\n",
        "To gain a deeper understanding of how similarity search operates, refer to the provided articles and references. These resources will offer a more detailed conceptual insight into the workings of similarity search algorithms and their applications in systems like ours.\n",
        "\n",
        "[Resource 1.](https://www.pinecone.io/learn/what-is-similarity-search/)\n",
        "\n",
        "[Resource 2.](https://python.langchain.com/docs/modules/data_connection/vectorstores/)"
      ],
      "metadata": {
        "id": "XSdBNAFuFog9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who is the instructor of Linear Algebra III?\""
      ],
      "metadata": {
        "id": "MtXjIjFOFn_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_chunks = faiss_index.similarity_search(question)\n",
        "best_chunk = relevant_chunks[0]\n",
        "\n",
        "print(str(best_chunk.metadata['source']) + \". Page: \" + str(best_chunk.metadata['page']) + \"\\n\\n\", best_chunk.page_content)"
      ],
      "metadata": {
        "id": "BCFVrRojMlm5",
        "outputId": "2458ac41-9491-4e6e-910b-c2f80410d375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IS883/Assignments/2023/IS883_HW4_syllabus_corpus/11___syllabus.pdf. Page: 0\n",
            "\n",
            " Math 406 – Linear Algebra III\n",
            "Winter 2009\n",
            "Course Syllabus\n",
            "Instructor: Anton Kaul\n",
            "Oﬃce: 25-312 (Faculty Oﬃces East)\n",
            "Phone: 6-1678\n",
            "email: akaul@calpoly.edu\n",
            "Oﬃce Hours: Monday 2-4, Tuesday 9-10, Thursday 9-10\n",
            "Course Web Page: www.calpoly.edu/ ∼akaul/teaching/Math406\n",
            "Textbook\n",
            "The text for the course is Friedberg, Insel, and Spence, Linear Algebra , 4th ed.\n",
            "Course Description\n",
            "In Math 406 we will continue our study of the fundamental concepts of Linear Algebra. Topics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Chain of Though: Riddle Me This..."
      ],
      "metadata": {
        "id": "OBMXXSxuNGX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have some fun with math riddles and explore the impact of different prompt engineering frameworks on solving them using AI."
      ],
      "metadata": {
        "id": "wDwpy8qJOzBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "riddle  = \"A man left 100 dollars to be divided between his two sons Alfred and Benjamin. If one third of Alfred’s legacy was taken from one-fourth of Benjamin’s, the remainder would be 11 dollars. How much is Alfred's legacy?\""
      ],
      "metadata": {
        "id": "IXt3n2vA4yww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools"
      ],
      "metadata": {
        "id": "VaGhcnQ8TlPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use LangChain debugging\n",
        "import langchain\n",
        "langchain.debug = False\n"
      ],
      "metadata": {
        "id": "SqNRZibNHe_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution 0: Zero-shot learning**.\n",
        "\n"
      ],
      "metadata": {
        "id": "P2YF3Vb8S1gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the llm\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-3.5-turbo\")\n",
        "print(\"\\n\", chat.invoke(riddle).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwhdDJPlTQUm",
        "outputId": "e6b58d32-997e-4ac8-f528-e1fb57d941ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Let x be the amount of the legacy of Alfred and y be the amount of the legacy of Benjamin.\n",
            "\n",
            "From the given information, we can create the following equations:\n",
            "\n",
            "x + y = 100 (equation 1)\n",
            "(1/3)x - (1/4)y = 11 (equation 2)\n",
            "\n",
            "To solve the system of equations, we can first simplify equation 2 by finding a common denominator:\n",
            "\n",
            "(4/12)x - (3/12)y = 11\n",
            "(4x - 3y)/12 = 11\n",
            "\n",
            "Now, we can multiply both sides by 12 to get rid of the denominator:\n",
            "\n",
            "4x - 3y = 132\n",
            "\n",
            "Next, we can use equation 1 to substitute y = 100 - x into the above equation:\n",
            "\n",
            "4x - 3(100 - x) = 132\n",
            "4x - 300 + 3x = 132\n",
            "7x - 300 = 132\n",
            "7x = 432\n",
            "x = 432 / 7\n",
            "x ≈ 61.71\n",
            "\n",
            "Therefore, Alfred's legacy is approximately 61.71 dollars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "1. What happens if we use a newer model?\n",
        "2. What happens if we change temperature?\n",
        "3. What happens if we use prompt engineering?"
      ],
      "metadata": {
        "id": "zfqsZCr2GVvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution 1: Zero-shot learning with a calculator**.\n",
        "\n",
        "\n",
        "Let's try enhancing the zero-shot learning approach by integrating a calculator tool with the language model. This setup aims to improve the accuracy and effectiveness of solving riddles, especially those involving mathematical elements.\n",
        "\n",
        "Use OpenAI playground with prompt engineering to trigger this.\n",
        "\n"
      ],
      "metadata": {
        "id": "X6Pl8n1tPMSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution 2: Chain of Thought (CoT)**.\n",
        "\n",
        "\n",
        "Finally, you'll guide the model through a step-by-step process, breaking down the solution into clear, logical steps. This CoT approach helps the AI model understand the reasoning process needed to arrive at the correct answer.\n"
      ],
      "metadata": {
        "id": "9rRbicTzTxST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "  {\n",
        "    \"question\": \"A woman left 200 dollars to be divided between her daughters. If one half of the Mary's inheritence was taken from one-quarter of the Sally's, the remainder would be 10 dollars. How much is Mary's inheritence?\"\n",
        ",\n",
        "    \"answer\":\n",
        "\"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: What's the sum equation?\n",
        "Intermediate answer: 200 = x + y\n",
        "Follow up: what's the fractions' equations?\n",
        "Intermediate answer: 0.25*y - 0.5*x = 10\n",
        "Follow up: get y in terms of x\n",
        "Intermediate answer: y = (10 + 0.5*x) / 0.25\n",
        "Follow up: substitute y into the first equation\n",
        "Intermediate answer: 200 = x + (10 + 0.5*x) / 0.25\n",
        "Follow up: solve for x\n",
        "Intermediate answer: x + (0.5/0.25)x = 200 - 10/0.25\n",
        "Follow up: simplify\n",
        "Intermediate answer: x + 2x = 200 - 40\n",
        "Follow up: Consolidate\n",
        "Intermediate answer: 3x = 160\n",
        "Follow up: get x\n",
        "Intermediate answer: x = 160/3\n",
        "The final answer: 53.333333\n",
        "\"\"\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "eQtM-uM97N2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n Answer: {answer} \\n ---------\")"
      ],
      "metadata": {
        "id": "kYcDGIvBILoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"Question: {input}\",\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "print(prompt.format(input=riddle))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmQPMVAX-N28",
        "outputId": "640c857a-21f3-49e5-acec-3669daacf96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: A woman left 200 dollars to be divided between her daughters. If one half of the Mary's inheritence was taken from one-quarter of the Sally's, the remainder would be 10 dollars. How much is Mary's inheritence?\n",
            " Answer: \n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: What's the sum equation?\n",
            "Intermediate answer: 200 = x + y\n",
            "Follow up: what's the fractions' equations?\n",
            "Intermediate answer: 0.25*y - 0.5*x = 10\n",
            "Follow up: get y in terms of x\n",
            "Intermediate answer: y = (10 + 0.5*x) / 0.25\n",
            "Follow up: substitute y into the first equation\n",
            "Intermediate answer: 200 = x + (10 + 0.5*x) / 0.25\n",
            "Follow up: solve for x\n",
            "Intermediate answer: x + (0.5/0.25)x = 200 - 10/0.25\n",
            "Follow up: simplify\n",
            "Intermediate answer: x + 2x = 200 - 40\n",
            "Follow up: Consolidate\n",
            "Intermediate answer: 3x = 160\n",
            "Follow up: get x\n",
            "Intermediate answer: x = 160/3\n",
            "The final answer: 53.333333\n",
            " \n",
            " ---------\n",
            "\n",
            "Question: A man left 100 dollars to be divided between his two sons Alfred and Benjamin. If one third of Alfred’s legacy was taken from one-fourth of Benjamin’s, the remainder would be 11 dollars. How much is Alfred's legacy?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, call the `llm` object with the template after properly substituting the riddle into it."
      ],
      "metadata": {
        "id": "MxAPdIyFXNDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat.invoke(prompt.format(input=riddle)).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u2FmoeS_wwA",
        "outputId": "d5cbcce3-92be-4f18-9cd3-6e8291a05e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            "Are follow up questions needed here: Yes\n",
            "Follow up: What's the sum equation?\n",
            "Intermediate answer: 100 = x + y\n",
            "Follow up: What's the fractions' equations?\n",
            "Intermediate answer: 0.25*y - 0.33*x = 11\n",
            "Follow up: Get y in terms of x\n",
            "Intermediate answer: y = (11 + 0.33*x) / 0.25\n",
            "Follow up: Substitute y into the first equation\n",
            "Intermediate answer: 100 = x + (11 + 0.33*x) / 0.25\n",
            "Follow up: Solve for x\n",
            "Intermediate answer: x + 1.32x = 100 - 11/0.25\n",
            "Follow up: Simplify\n",
            "Intermediate answer: 2.32x = 100 - 44\n",
            "Follow up: Consolidate\n",
            "Intermediate answer: 2.32x = 56\n",
            "Follow up: Get x\n",
            "Intermediate answer: x = 56 / 2.32\n",
            "The final answer: 24.137931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 ReAct"
      ],
      "metadata": {
        "id": "0DIYaE3xJhRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agents"
      ],
      "metadata": {
        "id": "Siwekwt7MzBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how we can use the wikipedia agent in `LangChain`"
      ],
      "metadata": {
        "id": "zYcqL0wzvkxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U wikipedia"
      ],
      "metadata": {
        "id": "A4acv-eR5cK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87633c54-cf2c-487c-ba7b-18df8d5d5aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=7287bb78fe7365c5a6de4e17630490615c9e71b80115d0f8ece3f1c9490a29a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's ask a question about GPT4 in Wikipedia"
      ],
      "metadata": {
        "id": "fmGRJPa9yfU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools, initialize_agent\n",
        "from langchain_community.utilities import SearchApiAPIWrapper\n",
        "import os\n",
        "# os.environ[\"SEARCHAPI_API_KEY\"] = userdata.get('SEARCHAPI_API_KEY')\n",
        "# SearchApiAPIWrapper()\n",
        "\n",
        "\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key)\n",
        "tools = load_tools([\"wikipedia\"], llm=chat) #\"llm-math\" is another possible tool for math. # , \"searchapi\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "agent= initialize_agent(\n",
        "    tools,\n",
        "    chat,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = True)\n",
        "\n",
        "msg = \"When was ChatGPT 4 released?\"\n",
        "\n",
        "agent(msg)"
      ],
      "metadata": {
        "id": "WWqM4Msn3tf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f07d4a4-ff78-475e-e863-4837b5f02abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find information about Mohannad Elhamod's date of birth\n",
            "Action: wikipedia\n",
            "Action Input: Mohannad Elhamod\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should try a different search query to find Mohannad Elhamod's date of birth\n",
            "Action: wikipedia\n",
            "Action Input: Mohannad Elhamod date of birth\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should try searching for Mohannad Elhamod's biography to find his date of birth\n",
            "Action: wikipedia\n",
            "Action Input: Mohannad Elhamod biography\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should try searching for Mohannad Elhamod's personal information to find his date of birth\n",
            "Action: wikipedia\n",
            "Action Input: Mohannad Elhamod personal information\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should try searching for Mohannad Elhamod's official website or social media profiles to find his date of birth\n",
            "Action: wikipedia\n",
            "Action Input: Mohannad Elhamod official website/social media\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI may need to look for other sources outside of Wikipedia to find Mohannad Elhamod's date of birth\n",
            "Final Answer: The date of birth for Mohannad Elhamod could not be found using Wikipedia.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"When was Mohannad Elhamod's date of birth\",\n",
              " 'output': 'The date of birth for Mohannad Elhamod could not be found using Wikipedia.'}"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is how you could list all tools available."
      ],
      "metadata": {
        "id": "ZEw0DugsN3zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.agents.get_all_tool_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oag_hdisNre_",
        "outputId": "d3f11267-4806-4469-d1d2-65e19c54dfcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sleep',\n",
              " 'wolfram-alpha',\n",
              " 'google-search',\n",
              " 'google-search-results-json',\n",
              " 'searx-search-results-json',\n",
              " 'bing-search',\n",
              " 'metaphor-search',\n",
              " 'ddg-search',\n",
              " 'google-lens',\n",
              " 'google-serper',\n",
              " 'google-scholar',\n",
              " 'google-finance',\n",
              " 'google-trends',\n",
              " 'google-jobs',\n",
              " 'google-serper-results-json',\n",
              " 'searchapi',\n",
              " 'searchapi-results-json',\n",
              " 'serpapi',\n",
              " 'dalle-image-generator',\n",
              " 'twilio',\n",
              " 'searx-search',\n",
              " 'merriam-webster',\n",
              " 'wikipedia',\n",
              " 'arxiv',\n",
              " 'golden-query',\n",
              " 'pubmed',\n",
              " 'human',\n",
              " 'awslambda',\n",
              " 'stackexchange',\n",
              " 'sceneXplain',\n",
              " 'graphql',\n",
              " 'openweathermap-api',\n",
              " 'dataforseo-api-search',\n",
              " 'dataforseo-api-search-json',\n",
              " 'eleven_labs_text2speech',\n",
              " 'google_cloud_texttospeech',\n",
              " 'read_file',\n",
              " 'reddit_search',\n",
              " 'news-api',\n",
              " 'tmdb-api',\n",
              " 'podcast-api',\n",
              " 'memorize',\n",
              " 'llm-math',\n",
              " 'open-meteo-api',\n",
              " 'requests',\n",
              " 'requests_get',\n",
              " 'requests_post',\n",
              " 'requests_patch',\n",
              " 'requests_put',\n",
              " 'requests_delete',\n",
              " 'terminal']"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    }
  ]
}